# -*- coding: utf-8 -*-
"""3 classes classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/155B_clxTrPGAdQdZSS7HsXiDv1r-L8Dx
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import scipy
from sklearn.model_selection import train_test_split
from sklearn import preprocessing
from sklearn.preprocessing import OneHotEncoder
import tensorflow as tf
from tensorflow.keras.utils import to_categorical
from tensorflow.keras.losses import categorical_crossentropy
from tensorflow.keras.optimizers import Adam
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.ensemble import RandomForestClassifier
from joblib import dump, load
from scipy.stats import mode
from matplotlib.ticker import MaxNLocator

import sklearn
print(sklearn.__version__)

df_ii = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/ii5.csv')
df_ii=df_ii.iloc[:, 5:]

#del df_ii['ver_acc']
df_ii = df_ii.drop(columns=[col for col in df_ii.columns if "6" in col])
df_ii = df_ii.drop(columns=[col for col in df_ii.columns if "nr" in col])
#idx=[1,2,7,38]
#df_ii=df_ii.iloc[:,idx]
[a,b]=df_ii.shape
print(b)
df_ii.insert(b, "classes", np.ones(a), True)

df_inw = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/inw5.csv')
df_inw=df_inw.iloc[: ,5:]
#del df_inw['ver_acc']
df_inw = df_inw.drop(columns=[col for col in df_inw.columns if "6" in col])
df_inw = df_inw.drop(columns=[col for col in df_inw.columns if "nr" in col])
idx=[1,2,7,38]
df_inw=df_inw.iloc[:,idx]

[a,b]=df_inw.shape

df_inw.insert(b, "classes",2*np.ones(a), True)

df_inw

df_o = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/o5.csv')
df_o=df_o.iloc[:, 5:]
#del df_o['ver_acc']
df_o = df_o.drop(columns=[col for col in df_o.columns if "6" in col])
df_o = df_o.drop(columns=[col for col in df_o.columns if "nr" in col])
idx=[1,2,7,38]
df_o=df_o.iloc[:,idx]
[a,b]=df_o.shape
df_o.insert(b, "classes", 0*np.ones(a), True)

frames2=[df_o,df_ii,df_inw]
res=pd.concat(frames2)

df_o

res_arr=res.to_numpy()

X=res_arr[:,0:b];
Y=res_arr[:,b];

X.shape

np.unique(Y)

X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y)



X_train

train_scaler = preprocessing.StandardScaler().fit(X_train)
X_train = train_scaler.transform(X_train)

X_test = train_scaler.transform(X_test)

y_train = to_categorical(Y_train)
y_test = to_categorical(Y_test)

X_test.shape

i=232
print(Y_train[i])
print(y_train[i,:])
print(Y_test[i])
print(y_test[i,:])

[s1,s2]=X_train.shape
[a,b]=y_train.shape
inp=tf.keras.Input(shape=(s2,))
inp2=tf.keras.layers.Dense(64,activation='relu')(inp)
inp2=tf.keras.layers.Dense(32,activation='relu')(inp)
inp2=tf.keras.layers.Dense(16,activation='relu')(inp2)
inp3=tf.keras.layers.Dense(8,activation='relu')(inp2)
out=tf.keras.layers.Dense(b,activation='softmax')(inp3)

mdl=tf.keras.Model(inp,out)
print(mdl.summary())

mdl.compile(loss=categorical_crossentropy,
              optimizer=Adam(),
              metrics=['accuracy']) # either loss or accuracy

callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath="DNN_3class_4feat.keras",
        save_best_only=False,
        monitor="val_acc"
    )
]

history = mdl.fit(X_train,y_train,
                    epochs = 50, batch_size=128,
                    validation_split=0.25,
                    callbacks = callbacks)

import os
print(os.listdir(os.getcwd()))

test_model = tf.keras.models.load_model('DNN_3class_4feat.keras')
test_loss, test_acc = test_model.evaluate(X_test,y_test)

print(f"Best Model's Test Accuracy: {test_acc:.3f}")



idx=np.where(Y_test==0)
X_test_o=np.squeeze(X_test[idx,:])
y_test_o=np.squeeze(y_test[idx,:])
Y_test_o=np.squeeze(Y_test[idx])
test_loss_o, test_acc_outdoor = test_model.evaluate(X_test_o,y_test_o)
print(f"Best Model's Test Accuracy for Outdoor: {test_acc_outdoor:.3f}")

idx=np.where(Y_test==1)
X_test_ii=np.squeeze(X_test[idx,:])
y_test_ii=np.squeeze(y_test[idx,:])
Y_test_ii=np.squeeze(Y_test[idx])
test_loss_ii, test_acc_ii = test_model.evaluate(X_test_ii,y_test_ii)
print(f"Best Model's Test Accuracy for Indoor Interior: {test_acc_ii:.3f}")

idx=np.where(Y_test==2)
X_test_inw=np.squeeze(X_test[idx,:])
y_test_inw=np.squeeze(y_test[idx,:])
Y_test_inw=np.squeeze(Y_test[idx])
test_loss_inw, test_acc_inw = test_model.evaluate(X_test_inw,y_test_inw)
print(f"Best Model's Test Accuracy for Indoor Near Window: {test_acc_inw:.3f}")

Y_test_inw



clf_tree=DecisionTreeClassifier(criterion='entropy',random_state=100,max_depth=10,min_samples_leaf=10)
clf_tree.fit(X_train, Y_train)
y_pred=clf_tree.predict(X_test)
print(f"Decision Tree Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")
clf_rf = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 42,max_depth=10,min_samples_leaf=10)
clf_rf.fit(X_train, Y_train)
y_pred=clf_rf.predict(X_test)
print(f"Random Forest Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

dump(clf_tree, 'clf_tree_3class_4feat.joblib')
dump(clf_rf, 'clf_rf_3class_4feat.joblib')

y_pred=test_model.predict(X_test)
y_pred=np.argmax(y_pred,axis=1)
print(f"DNN Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

y_pred_o=test_model.predict(X_test_o)
y_pred_o=np.argmax(y_pred_o,axis=1)
print(f"DNN O to O: {np.mean(np.where(y_pred_o==0,1,0)):3f}")
print(f"DNN O to II: {np.mean(np.where(y_pred_o==1,1,0)):3f}")
print(f"DNN O to INW: {np.mean(np.where(y_pred_o==2,1,0)):3f}")

y_pred_ii=test_model.predict(X_test_ii)
y_pred_ii=np.argmax(y_pred_ii,axis=1)
print(f"DNN II to O: {np.mean(np.where(y_pred_ii==0,1,0)):3f}")
print(f"DNN II to II: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
print(f"DNN II to INW: {np.mean(np.where(y_pred_ii==2,1,0)):3f}")

y_pred_inw=test_model.predict(X_test_inw)
y_pred_inw=np.argmax(y_pred_inw,axis=1)
print(f"DNN INW to O: {np.mean(np.where(y_pred_inw==0,1,0)):3f}")
print(f"DNN INW to II: {np.mean(np.where(y_pred_inw==1,1,0)):3f}")
print(f"DNN INW to INW: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")



y_pred=clf_tree.predict(X_test)
print(f"DT Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

y_pred_o=clf_tree.predict(X_test_o)
print(f"DT O to O: {np.mean(np.where(y_pred_o==0,1,0)):3f}")
print(f"DT O to II: {np.mean(np.where(y_pred_o==1,1,0)):3f}")
print(f"DT O to INW: {np.mean(np.where(y_pred_o==2,1,0)):3f}")
y_pred_ii=clf_tree.predict(X_test_ii)
print(f"DT II to O: {np.mean(np.where(y_pred_ii==0,1,0)):3f}")
print(f"DT II to II: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
print(f"DT II to INW: {np.mean(np.where(y_pred_ii==2,1,0)):3f}")

y_pred_inw=clf_tree.predict(X_test_inw)
print(f"DT INW to O: {np.mean(np.where(y_pred_inw==0,1,0)):3f}")
print(f"DT INW to II: {np.mean(np.where(y_pred_inw==1,1,0)):3f}")
print(f"DT INW to INW: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

y_pred=clf_rf.predict(X_test)
print(f"RF Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

y_pred_o=clf_rf.predict(X_test_o)
print(f"RF O to O: {np.mean(np.where(y_pred_o==0,1,0)):3f}")
print(f"RF O to II: {np.mean(np.where(y_pred_o==1,1,0)):3f}")
print(f"RF O to INW: {np.mean(np.where(y_pred_o==2,1,0)):3f}")

y_pred_ii=clf_rf.predict(X_test_ii)
print(f"RF II to O: {np.mean(np.where(y_pred_ii==0,1,0)):3f}")
print(f"RF II to II: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
print(f"RF II to INW: {np.mean(np.where(y_pred_ii==2,1,0)):3f}")

y_pred_inw=clf_rf.predict(X_test_inw)
print(f"RF INW to O: {np.mean(np.where(y_pred_inw==0,1,0)):3f}")
print(f"RF INW to II: {np.mean(np.where(y_pred_inw==1,1,0)):3f}")
print(f"RF INW to INW: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

def most_frequent(row):
    unique, counts = np.unique(row, return_counts=True)
    return unique[np.argmax(counts)]

def three_classes_MV(X_test,Y_test,dnn_mdl,dt_mdl,rf_mdl,duration):
  idx=np.where(Y_test==0)
  X_test_o=np.squeeze(X_test[idx,:])
  Y_test_o=np.squeeze(Y_test[idx])


  idx=np.where(Y_test==1)
  X_test_ii=np.squeeze(X_test[idx,:])
  Y_test_ii=np.squeeze(Y_test[idx])

  idx=np.where(Y_test==2)
  X_test_inw=np.squeeze(X_test[idx,:])
  Y_test_inw=np.squeeze(Y_test[idx])

  ## DNN part
  y_pred_ii=dnn_mdl.predict(X_test_ii)
  y_pred_ii=np.argmax(y_pred_ii,axis=1)

  ## DNN part
  y_pred_inw=dnn_mdl.predict(X_test_inw)
  y_pred_inw=np.argmax(y_pred_inw,axis=1)

  y_pred_o=dnn_mdl.predict(X_test_o)
  y_pred_o=np.argmax(y_pred_o,axis=1)
  print("DNN Test Accuracy for  Outdoors "+ f": {np.mean(np.where(y_pred_o==0,1,0)):3f}")
  print("DNN Test Accuracy for  Indoors Interior "+ f": {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
  print("DNN Test Accuracy for  Indoors Near Window "+ f": {np.mean(np.where(y_pred_inw==2,1,0)):3f}")


  ## MAjority Voting
  y_predmv_o=y_pred_o[0:int(np.floor(len(y_pred_o)/duration)*duration)]
  y_predmv_o=np.reshape(y_predmv_o,(-1,duration))
  y_predmv_o=np.transpose(y_predmv_o)
  y_predmv_o=np.apply_along_axis(most_frequent, 0, y_predmv_o)
  print("DNN Test Accuracy for Outdoors " + f" with MV method: {np.mean(np.where(y_predmv_o==0,1,0)):3f}")

  ## MAjority Voting
  y_predmv_ii=y_pred_ii[0:int(np.floor(len(y_pred_ii)/duration)*duration)]
  y_predmv_ii=np.reshape(y_predmv_ii,(-1,duration))
  y_predmv_ii=np.transpose(y_predmv_ii)
  y_predmv_ii=np.apply_along_axis(most_frequent, 0, y_predmv_ii)
  print("DNN Test Accuracy for Indoor Interior " + f" with MV method: {np.mean(np.where(y_predmv_ii==1,1,0)):3f}")

    ## MAjority Voting
  y_predmv_inw=y_pred_inw[0:int(np.floor(len(y_pred_inw)/duration)*duration)]
  y_predmv_inw=np.reshape(y_predmv_inw,(-1,duration))
  y_predmv_inw=np.transpose(y_predmv_inw)
  y_predmv_inw=np.apply_along_axis(most_frequent, 0, y_predmv_inw)
  print("DNN Test Accuracy for Indoor Near Window " + f" with MV method: {np.mean(np.where(y_predmv_inw==2,1,0)):3f}")


  ## DT part
  y_pred_ii=dt_mdl.predict(X_test_ii)
  y_pred_inw=dt_mdl.predict(X_test_inw)
  y_pred_o=dt_mdl.predict(X_test_o)
  print("DT Test Accuracy for  Outdoors "+ f": {np.mean(np.where(y_pred_o==0,1,0)):3f}")
  print("DT Test Accuracy for  Indoors Interior "+ f": {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
  print("DT Test Accuracy for  Indoors Near Window "+ f": {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

   ## MAjority Voting
  y_predmv_o=y_pred_o[0:int(np.floor(len(y_pred_o)/duration)*duration)]
  y_predmv_o=np.reshape(y_predmv_o,(-1,duration))
  y_predmv_o=np.transpose(y_predmv_o)
  y_predmv_o=np.apply_along_axis(most_frequent, 0, y_predmv_o)
  print("DT Test Accuracy for Outdoors " + f" with MV method: {np.mean(np.where(y_predmv_o==0,1,0)):3f}")

  ## MAjority Voting
  y_predmv_ii=y_pred_ii[0:int(np.floor(len(y_pred_ii)/duration)*duration)]
  y_predmv_ii=np.reshape(y_predmv_ii,(-1,duration))
  y_predmv_ii=np.transpose(y_predmv_ii)
  y_predmv_ii=np.apply_along_axis(most_frequent, 0, y_predmv_ii)
  print("DT Test Accuracy for Indoor Interior " + f" with MV method: {np.mean(np.where(y_predmv_ii==1,1,0)):3f}")

    ## MAjority Voting
  y_predmv_inw=y_pred_inw[0:int(np.floor(len(y_pred_inw)/duration)*duration)]
  y_predmv_inw=np.reshape(y_predmv_inw,(-1,duration))
  y_predmv_inw=np.transpose(y_predmv_inw)
  y_predmv_inw=np.apply_along_axis(most_frequent, 0, y_predmv_inw)
  print("DT Test Accuracy for Indoor Near Window " + f" with MV method: {np.mean(np.where(y_predmv_inw==2,1,0)):3f}")



  ## RF part
  y_pred_ii=rf_mdl.predict(X_test_ii)
  y_pred_inw=rf_mdl.predict(X_test_inw)
  y_pred_o=rf_mdl.predict(X_test_o)
  print("RF Test Accuracy for  Outdoors "+ f": {np.mean(np.where(y_pred_o==0,1,0)):3f}")
  print("RF Test Accuracy for  Indoors Interior "+ f": {np.mean(np.where(y_pred_ii==1,1,0)):3f}")
  print("RF Test Accuracy for  Indoors Near Window "+ f": {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

  ## MAjority Voting
  y_predmv_o=y_pred_o[0:int(np.floor(len(y_pred_o)/duration)*duration)]
  y_predmv_o=np.reshape(y_predmv_o,(-1,duration))
  y_predmv_o=np.transpose(y_predmv_o)
  y_predmv_o=np.apply_along_axis(most_frequent, 0, y_predmv_o)
  print("RF Test Accuracy for Outdoors " + f" with MV method: {np.mean(np.where(y_predmv_o==0,1,0)):3f}")

  ## MAjority Voting
  y_predmv_ii=y_pred_ii[0:int(np.floor(len(y_pred_ii)/duration)*duration)]
  y_predmv_ii=np.reshape(y_predmv_ii,(-1,duration))
  y_predmv_ii=np.transpose(y_predmv_ii)
  y_predmv_ii=np.apply_along_axis(most_frequent, 0, y_predmv_ii)
  print("RF Test Accuracy for Indoor Interior " + f" with MV method: {np.mean(np.where(y_predmv_ii==1,1,0)):3f}")

   ## MAjority Voting
  y_predmv_inw=y_pred_inw[0:int(np.floor(len(y_pred_inw)/duration)*duration)]
  y_predmv_inw=np.reshape(y_predmv_inw,(-1,duration))
  y_predmv_inw=np.transpose(y_predmv_inw)
  y_predmv_inw=np.apply_along_axis(most_frequent, 0, y_predmv_inw)
  print("RF Test Accuracy for Indoor Near Window " + f" with MV method: {np.mean(np.where(y_predmv_inw==2,1,0)):3f}")

dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
duration=6
three_classes_MV(X_test,Y_test,dnn_mdl,dt_mdl,rf_mdl,duration)

y_pred_ii=clf_tree.predict(X_test_ii)
print(f"Decision Tree Test Accuracy for Indoor Interior: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")

y_pred_inw=clf_tree.predict(X_test_inw)
print(f"Decision Tree Test Accuracy for Indoor Near Window: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

clf_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)



y_pred=clf_tree.predict(X_test)
print(f"Decision Tree Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

y_pred_o=clf_tree.predict(X_test_o)
print(f"Decision Tree Test Accuracy for Outdoor: {np.mean(np.where(y_pred_o==0,1,0)):3f}")

y_pred_ii=clf_tree.predict(X_test_ii)
print(f"Decision Tree Test Accuracy for Indoor Interior: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")

y_pred_inw=clf_tree.predict(X_test_inw)
print(f"Decision Tree Test Accuracy for Indoor Near Window: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

clf_rf = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 42)


clf_rf.fit(X_train, Y_train)
y_pred=clf_rf.predict(X_test)
print(f"Random Forest Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

y_pred_o=clf_rf.predict(X_test_o)
print(f"Random Forest Test Accuracy for Outdoor: {np.mean(np.where(y_pred_o==0,1,0)):3f}")

y_pred_ii=clf_rf.predict(X_test_ii)
print(f"Random Forest Test Accuracy for Indoor Interior: {np.mean(np.where(y_pred_ii==1,1,0)):3f}")

y_pred_inw=clf_rf.predict(X_test_inw)
print(f"Random Forest Test Accuracy for Indoor Near Window: {np.mean(np.where(y_pred_inw==2,1,0)):3f}")

"""# DC Data"""

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
del df_atl_in['ver_acc']
#df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "6" in col])
df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "nr" in col])
idx=[1,6,40]

df_atl_in=df_atl_in.iloc[:,idx]
print(df_atl_in.columns)
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", 1*np.ones(a), True)



frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
Y_atl[2]=2

X_atl = train_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"DNN Test Accuracy for DC indoor interrior  data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for DC indoor interrior data : {np.mean(np.where(y_pred_atl==1,1,0))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for DC indoor interrior  data : {np.mean(np.where(y_pred_atl==1,1,0))}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_inw.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
del df_atl_in['ver_acc']
#df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "6" in col])
df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "nr" in col])
idx=[1,6,40]

df_atl_in=df_atl_in.iloc[:,idx]
print(df_atl_in.columns)
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", 2*np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
Y_atl[2]=2

X_atl = train_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"DNN Test Accuracy for DC indoor near window  data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for DC indoor near window data : {np.mean(np.where(y_pred_atl==2,1,0))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for DC indoor near window  data : {np.mean(np.where(y_pred_atl==2,1,0))}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_o.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
del df_atl_in['ver_acc']
#df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "6" in col])
df_atl_in = df_atl_in.drop(columns=[col for col in df_atl_in.columns if "nr" in col])
idx=[1,6,40]

df_atl_in=df_atl_in.iloc[:,idx]
print(df_atl_in.columns)
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", 0*np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];

X_atl = train_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"DNN Test Accuracy for DC outdoors  data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for DC outdoors data : {np.mean(np.where(y_pred_atl==0,1,0))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for DC outdoors  data : {np.mean(np.where(y_pred_atl==0,1,0))}")

!pip install git+https://github.com/slundberg/shap.git

import shap

explainer=shap.Explainer(rf_mdl)
shapvalues=explainer(X_test)

np.shape(shapvalues.values)

np.shape(X_test)

shap.summary_plot(shapvalues[0,0], X_test)

shap.plots.beeswarm(shapvalues)

shapvalues[0]

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv';
class_label=1
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Indoor Interrior"
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag)

df=pd.read_csv(dir_file)
  df=df.iloc[:, 5:]
  [a,b]=df.shape
  df.insert(b, "classes", class_label*np.ones(a), True)
  frames=[df]
  df_res=pd.concat(frames)
  res_arr=df_res.to_numpy()
  X=res_arr[:,:b];
  Y=res_arr[:,b];
  X=scaler.transform(X)
  y=to_categorical(Y)

  ## DNN part
  y_pred=dnn_mdl.predict(X)
  y_pred=np.argmax(y_pred,axis=1)
  print("DNN Test Accuracy for " +tag+ f": {np.mean(np.where(y_pred==class_label,1,0)):3f}")

y_predmv=y_pred[0:int(np.floor(len(y_pred)/6)*6)]
  y_predmv=np.reshape(y_predmv,(-1,6))
  y_predmv=np.transpose(y_predmv)
  y_predmv=np.sum(y_predmv,axis=0)/6
  y_predmv=[np.where(y_predmv>0.5,1,0)]
  y_mv=np.ones(int(len(y_predmv)))

shape(y_predmv)

def most_frequent(row):
    unique, counts = np.unique(row, return_counts=True)
    return unique[np.argmax(counts)]

np.apply_along_axis()

e=np.apply_along_axis(most_frequent, 0, y_predmv)

e.shape

Y

"""# DC _DAta _ 5 sec majority voting"""

def three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration):
  df=pd.read_csv(dir_file)
  df=df.iloc[:, 5:]
  #del df['ver_acc']
  #df = df.drop(columns=[col for col in df.columns if "6" in col])
  #df = df.drop(columns=[col for col in df.columns if "nr" in col])
  #idx=[1,2,7,38]

  #df=df.iloc[:,idx]
  print(df_atl.columns)
  [a,b]=df.shape
  print(a)
  df.insert(b, "classes", class_label*np.ones(a), True)
  print(len(df.columns))
  frames=[df]
  df_res=pd.concat(frames)
  res_arr=df_res.to_numpy()
  X=res_arr[:,:b];
  Y=res_arr[:,b];
  X=scaler.transform(X)
  y=to_categorical(Y)

  ## DNN part
  y_pred=dnn_mdl.predict(X)
  y_pred=np.argmax(y_pred,axis=1)
  print("DNN Test Accuracy for " +tag+ f": {np.mean(np.where(y_pred==class_label,1,0)):3f}")

  ## MAjority Voting
  y_predmv=y_pred[0:int(np.floor(len(y_pred)/duration)*duration)]
  y_predmv=np.reshape(y_predmv,(-1,duration))
  y_predmv=np.transpose(y_predmv)
  y_predmv=np.apply_along_axis(most_frequent, 0, y_predmv)
  print("DNN Test Accuracy for " +tag+ f" with MV method: {np.mean(np.where(y_predmv==class_label,1,0)):3f}")

  ## DT part
  y_pred=dt_mdl.predict(X)

  print("DT Test Accuracy for " +tag+ f": {np.mean(np.where(y_pred==class_label,1,0)):3f}")

  ## MAjority Voting
  y_predmv=y_pred[0:int(np.floor(len(y_pred)/duration)*duration)]
  y_predmv=np.reshape(y_predmv,(-1,duration))
  y_predmv=np.transpose(y_predmv)
  y_predmv=np.apply_along_axis(most_frequent, 0, y_predmv)
  print("DT Test Accuracy for " +tag+ f" with MV method: {np.mean(np.where(y_predmv==class_label,1,0)):3f}")

  ## RF part
  y_pred=rf_mdl.predict(X)
  print("RF Test Accuracy for " +tag+ f": {np.mean(np.where(y_pred==class_label,1,0)):3f}")

  ## MAjority Voting
  y_predmv=y_pred[0:int(np.floor(len(y_pred)/duration)*duration)]
  y_predmv=np.reshape(y_predmv,(-1,duration))
  y_predmv=np.transpose(y_predmv)
  y_predmv=np.apply_along_axis(most_frequent, 0, y_predmv)
  print("RF Test Accuracy for " +tag+ f" with MV method: {np.mean(np.where(y_predmv==class_label,1,0)):3f}")
  return [X,y_pred]

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_inw5.csv';
class_label=1
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Indoor Interrior"
duration=6
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration)

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv';
class_label=1
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Indoor Interrior"
duration=5000
X,y_pred=three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration)



plt.scatter(X[y_pred_corr,1],X[y_pred_corr,2])
plt.scatter(X[y_pred_incorr,1],X[y_pred_incorr,2])
plt.show()

df_dc_in=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
plt.scatter(df_dc_in.hor_acc,df_dc_in.ver_acc)
df_dc_o=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_o5.csv')
plt.scatter(df_dc_o.hor_acc,df_dc_o.ver_acc)

pp[0]

plt.stem(pp[0],np.ones(len(pp[0])))

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_inw5.csv';
class_label=2
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Indoor Near Window"
duration=6
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration)

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_inw5.csv';
class_label=2
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Indoor Near Window"
duration=480
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration)

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_o5.csv';
class_label=0
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="DC Outdoor"
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag)

"""## **ATLANTA DATASET**

"""

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech20_out.csv';
class_label=0
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="Gtech20_out"
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag)

dir_file='/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech20_out5.csv';
class_label=0
scaler=train_scaler
dnn_mdl=test_model
dt_mdl=clf_tree
rf_mdl=clf_rf
tag="Gtech20_out"
three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag)





df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech20_out.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", 0*np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];

X_atl = train_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
y_pred=test_model.predict(X_atl)
y_pred=np.argmax(y_pred,axis=1)
print(f"Best Model's Test Accuracy for DNN indoors: {np.sum(np.where(y_pred==0,1,0))/len(y_pred):3f}")


y_predmv=y_pred[0:int(np.floor(len(y_pred)/6)*6)]
y_predmv=np.reshape(y_predmv,(-1,6))
y_predmv=np.transpose(y_predmv)
y_predmv=np.where(y_predmv==0,1,0)
y_predmv=np.sum(y_predmv,axis=0)/6
y_predmv=[np.where(y_predmv>=0.5,1,0)]
y_atl_mv=np.ones(int(len(y_predmv)))

print(f"Best Model's Test Accuracy for DNN indoors with MV method: {np.sum(np.where(y_predmv[0]==1,1,0))/len(y_predmv[0]):3f}")

y_pred_atl=clf_tree.predict(X_atl)

print(f"Decision Tree Test Accuracy for DC indoors data : {np.sum(np.where(y_pred_atl==0,1,0))/len(y_pred_atl):3f}")

y_predmv=y_pred_atl[0:int(np.floor(len(y_pred)/6)*6)]
y_predmv=np.reshape(y_predmv,(-1,6))
y_predmv=np.transpose(y_predmv)
y_predmv=np.where(y_predmv==0,1,0)
y_predmv=np.sum(y_predmv,axis=0)/6
y_predmv=[np.where(y_predmv>=0.5,1,0)]
y_atl_mv=np.ones(int(len(y_predmv)))

print(f"Best Model's Test Accuracy for DC indoors with MV method: {np.sum(np.where(y_predmv[0]==1,1,0))/len(y_predmv[0]):3f}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for RF indoors  data : {np.sum(np.where(y_pred_atl==0,1,0))/len(y_pred_atl):3f}")

y_predmv=y_pred_atl[0:int(np.floor(len(y_pred)/6)*6)]
y_predmv=np.reshape(y_predmv,(-1,6))
y_predmv=np.transpose(y_predmv)
y_predmv=np.where(y_predmv==0,1,0)
y_predmv=np.sum(y_predmv,axis=0)/6
y_predmv=[np.where(y_predmv>=0.5,1,0)]
y_atl_mv=np.ones(int(len(y_predmv)))

print(f"Best Model's Test Accuracy for RF indoors with MV method: {np.sum(np.where(y_predmv[0]==1,1,0))/len(y_predmv[0]):3f}")

feature_importances = clf_tree.feature_importances_
sorted_indices = feature_importances.argsort()[::-1]

sorted_indices

colname = df_inw.columns[sorted_indices]
print (colname)

feature_importances_rf = clf_rf.feature_importances_
sorted_indices_rf = feature_importances_rf.argsort()[::-1]

sorted_indices_rf

colname = df_inw.columns[sorted_indices_rf]
print (colname)

def CDF(data):
  data_sorted = np.sort(data)

  # Calculate the cumulative distribution values
  cdf = np.arange(1, len(data_sorted) + 1) / len(data_sorted)

  return[data_sorted,cdf]



X,y_pred=three_classes(dir_file,class_label,scaler,dnn_mdl,dt_mdl,rf_mdl,tag,duration)

y_pred_corr=np.where(y_pred==1)
y_pred_incorr=np.where(y_pred!=1)

df_inw

idx=0
[a,b]=CDF(df_inw.hor_acc)
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_ii.hor_acc)
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_o.hor_acc)
plt.plot(a,b,linewidth=2)
plt.xlim([0,200])
plt.legend(['II','INW','O'],fontsize='x-large')
plt.xlabel("Radius of 68% Confidense (m)",fontsize='large')
plt.ylabel("CDF",fontsize='x-large')
plt.grid("True")

idx=1
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_o.iloc[:,idx])
plt.plot(a,b,linewidth=2)
plt.xlim([0,30])
plt.legend(['II','INW','O'],fontsize='x-large')
plt.xlabel("Radius of 68% Confidense (m)",fontsize='x-large')
plt.ylabel("CDF",fontsize='x-large')
plt.grid("True")

idx=2
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_o.iloc[:,idx])
plt.plot(a,b,linewidth=2)
plt.legend(['II','INW','O'],fontsize='x-large')
plt.xlabel("# of Unique BSSIDs",fontsize='x-large')
plt.ylabel("CDF",fontsize='x-large')
plt.grid("True")

idx=3
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b,linewidth=2)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b,linewidth=2)
df_oo=df_o
df_oo = df_oo.loc[df_oo['max_of_wifi_5'] < 0]
[a,b]=CDF(df_oo.iloc[:,idx])
plt.plot(a,b,linewidth=2)
#df_dc_in=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
#df_dc_in=df_dc_in.iloc[:,5:]
#[a,b]=CDF(df_dc_in.iloc[y_pred_incorr[0],idx])
#plt.plot(a,b)
plt.legend(['II','INW','O'],fontsize='x-large')
plt.xlabel("Max. of RSSI (dBm)",fontsize='x-large')
plt.ylabel("CDF",fontsize='x-large')
plt.grid("True")

df_ii.columns

a.shape

idx=0
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_o.iloc[:,idx])
plt.plot(a,b)
#df_dc_in=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
#df_dc_in=df_dc_in.iloc[:,5:]
#[a,b]=CDF(df_dc_in.iloc[y_pred_incorr[0],idx])
#plt.plot(a,b)
plt.legend(['II','INW','O'])
plt.title("HOR ACC")
plt.grid("True")

idx=11
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_o.iloc[:,idx])
plt.plot(a,b)
df_dc_in=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
df_dc_in=df_dc_in.iloc[:,5:]
[a,b]=CDF(df_dc_in.iloc[y_pred_incorr[0],idx])
plt.plot(a,b)
plt.legend(['II','INW','O','Misclassified DC II'])
plt.title("Num of WIFI 6")
plt.grid("True")

"""# After Adding 30% of testing dataset"""

df_dc = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
df_dc=df_dc.iloc[:,5:]
df_dc_train=df_dc.iloc[:int(np.floor(0.3*len(df_ii))),:]
[a,b]=df_dc_train.shape
df_dc_train.insert(b, "classes", np.ones(a), True)
df_dc_test=df_dc.iloc[int(np.floor(0.3*len(df_ii)))+1:,:]
[a,b]=df_dc_test.shape
df_dc_test.insert(b, "classes", np.ones(a), True)

idx=11
[a,b]=CDF(df_inw.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_ii.iloc[:,idx])
plt.plot(a,b)
[a,b]=CDF(df_o.iloc[:,idx])
plt.plot(a,b)
df_dc_in=pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/dc_ii5.csv')
df_dc_in=df_dc_in.iloc[:,5:]
[a,b]=CDF(df_dc_in.iloc[y_pred_incorr[0],idx])
plt.plot(a,b)
plt.legend(['II','INW','O','Misclassified DC II'])
plt.title("NUM of WIFI 5")
plt.grid("True")

df_ii_new=df_ii.iloc[:int(np.floor(0.7*len(df_ii))),:]

res

frames2=[df_o,df_ii_new,df_dc_train,df_inw]
res=pd.concat(frames2)
res_arr=res.to_numpy()
X=res_arr[:,0:b];
Y=res_arr[:,b];
print(Y)
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, stratify=Y,shuffle=True)
train_scaler = preprocessing.StandardScaler().fit(X_train)
X_train = train_scaler.transform(X_train)
y_train = to_categorical(Y_train)
y_test = to_categorical(Y_test)

[s1,s2]=X_train.shape
[a,b]=y_train.shape
inp=tf.keras.Input(shape=(s2,))
inp2=tf.keras.layers.Dense(64,activation='relu')(inp)
inp2=tf.keras.layers.Dense(32,activation='relu')(inp)
inp2=tf.keras.layers.Dense(16,activation='relu')(inp2)
inp3=tf.keras.layers.Dense(8,activation='relu')(inp2)
out=tf.keras.layers.Dense(b,activation='softmax')(inp3)

mdl2=tf.keras.Model(inp,out)
print(mdl2.summary())

mdl2.compile(loss=categorical_crossentropy,
              optimizer=Adam(),
              metrics=['accuracy']) # either loss or accuracy

callbacks = [
    tf.keras.callbacks.ModelCheckpoint(
        filepath="DNN_3class_b.keras",
        save_best_only=False,
        monitor="val_acc"
    )
]

history = mdl2.fit(X_train,y_train,
                    epochs = 50, batch_size=128,
                    validation_split=0.25,
                    callbacks = callbacks)

Y

test_model = tf.keras.models.load_model('DNN_3class_b.keras')
test_loss, test_acc = mdl2.evaluate(X_test,y_test)

print(f"Best Model's Test Accuracy: {test_acc:.3f}")

y_pred=mdl2.predict(X_test)
y_pred=np.argmax(y_pred,axis=1)

np.unique(y_pred)

y_test



clf_tree=DecisionTreeClassifier(criterion='entropy',random_state=100,max_depth=10,min_samples_leaf=10)
clf_tree.fit(X_train, Y_train)
y_pred=clf_tree.predict(X_test)
print(f"Decision Tree Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")
clf_rf = RandomForestClassifier(n_estimators = 5, criterion = 'entropy', random_state = 42,max_depth=10,min_samples_leaf=10)
clf_rf.fit(X_train, Y_train)
y_pred=clf_rf.predict(X_test)
print(f"Random Forest Test Accuracy : {np.mean(np.where(y_pred-Y_test==0,1,0))}")

idx=np.where(Y_test==0)
X_test_o=np.squeeze(X_test[idx,:])
y_test_o=np.squeeze(y_test[idx,:])
Y_test_o=np.squeeze(Y_test[idx])
test_loss_o, test_acc_outdoor = test_model.evaluate(X_test_o,y_test_o)
print(f"Best Model's Test Accuracy for Outdoor: {test_acc_outdoor:.3f}")

idx=np.where(Y_test==1)
X_test_ii=np.squeeze(X_test[idx,:])
y_test_ii=np.squeeze(y_test[idx,:])
Y_test_ii=np.squeeze(Y_test[idx])
test_loss_ii, test_acc_ii = test_model.evaluate(X_test_ii,y_test_ii)
print(f"Best Model's Test Accuracy for Indoor Interior: {test_acc_ii:.3f}")

idx=np.where(Y_test==2)
X_test_inw=np.squeeze(X_test[idx,:])
y_test_inw=np.squeeze(y_test[idx,:])
Y_test_inw=np.squeeze(Y_test[idx])
test_loss_inw, test_acc_inw = test_model.evaluate(X_test_inw,y_test_inw)
print(f"Best Model's Test Accuracy for Indoor Near Window: {test_acc_inw:.3f}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech20_a.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
atl_scaler = preprocessing.StandardScaler().fit(X_atl)
X_atl = atl_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"Best Model's Test Accuracy for ATLANTA Gtech20 windows indoor data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for ATLANTA Gtech20 windows indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for ATLANTA Gtech20 windows indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech20_b.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
atl_scaler = preprocessing.StandardScaler().fit(X_atl)
X_atl = atl_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"Best Model's Test Accuracy for ATLANTA Gtech20 near-window indoor data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for ATLANTA Gtech20 near-window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for ATLANTA Gtech20 near-window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech9_a.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
atl_scaler = preprocessing.StandardScaler().fit(X_atl)
X_atl = atl_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"Best Model's Test Accuracy for ATLANTA Gtech9 near-window indoor data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for ATLANTA Gtech9 near-window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for ATLANTA Gtech9 near-window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

df_atl_in = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/Gtech9_b.csv')
df_atl_in=df_atl_in.iloc[:, 5:]
[a,b]=df_atl_in.shape
print(a)
df_atl_in.insert(b, "classes", np.ones(a), True)


frames3=[df_atl_in]
df_atl=pd.concat(frames3)

res_atl=df_atl.to_numpy()
X_atl=res_atl[:,:b];
Y_atl=res_atl[:,b];
atl_scaler = preprocessing.StandardScaler().fit(X_atl)
X_atl = atl_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)
atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"Best Model's Test Accuracy for ATLANTA Gtech9 window indoor data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for ATLANTA Gtech9 window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for ATLANTA Gtech9 window indoor data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

atl_scaler = preprocessing.StandardScaler().fit(X_atl)
X_atl = atl_scaler.transform(X_atl)
y_atl = to_categorical(Y_atl)

atl_loss, atl_acc = test_model.evaluate(X_atl,y_atl)
print(f"Best Model's Test Accuracy for ATLANTA data: {atl_acc:.3f}")
y_pred_atl=clf_tree.predict(X_atl)
print(f"Decision Tree Test Accuracy for ATALANTA data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

y_pred_atl=clf_rf.predict(X_atl)
print(f"Random Forest Test Accuracy for ATALANTA data : {1-np.mean(np.abs(y_pred_atl-Y_atl))}")

"""# Data Analysis"""

df_ii = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/ii5.csv')
df_inw = pd.read_csv('/content/drive/Shareddrives/Indoor_Outdoor_Classification_Paper/inw5.csv')
frame_in=[df_ii,df_inw]
df_i=pd.concat(frame_in)

df_i

def weighted_mean_db(w1,v1,w2,v2):
  v1_lin=10**(v1/10)
  v2_lin=10**(v2/10)
  temp=10*np.log10((w1*v1_lin+w2*v2_lin)/(w1+w2))
  return temp.replace('NaN',0)

# Indoors


LTE_NUM_II_f1=df_ii.lte_num_of_f1
LTE_NUM_II_f2=df_ii.lte_num_of_f2
LTE_RSRP_Count_II=LTE_NUM_II_f1+LTE_NUM_II_f2
LTE_RSRP_AVG_II=weighted_mean_db(LTE_NUM_II_f1,df_ii.lte_avg_rsrp_f1,LTE_NUM_II_f2,df_ii.lte_avg_rsrp_f2)
LTE_RSRP_Max_II=df_ii[['lte_max_rsrp_f1','lte_max_rsrp_f2']].max(axis=1)
LTE_RSRP_Min_II=df_ii[['lte_min_rsrp_f1','lte_min_rsrp_f2']].min(axis=1)


LTE_RSSI_Count_II=LTE_NUM_II_f1+LTE_NUM_II_f2
LTE_RSSI_AVG_II=weighted_mean_db(LTE_NUM_II_f1,df_ii.lte_avg_rssi_f1,LTE_NUM_II_f2,df_ii.lte_avg_rssi_f2)
LTE_RSSI_Max_II=df_ii[['lte_max_rssi_f1','lte_max_rssi_f2']].max(axis=1)
LTE_RSSI_Min_II=df_ii[['lte_min_rssi_f1','lte_min_rssi_f2']].min(axis=1)

LTE_RSRQ_Count_II=LTE_NUM_II_f1+LTE_NUM_II_f2
LTE_RSRQ_AVG_II=weighted_mean_db(LTE_NUM_II_f1,df_ii.lte_avg_rsrq_f1,LTE_NUM_II_f2,df_ii.lte_avg_rsrq_f2)
LTE_RSRQ_Max_II=df_ii[['lte_max_rsrq_f1','lte_max_rsrq_f2']].max(axis=1)
LTE_RSRQ_Min_II=df_ii[['lte_min_rsrq_f1','lte_min_rsrq_f2']].min(axis=1)


# Indoor NearWindow

LTE_NUM_INW_f1=df_inw.lte_num_of_f1
LTE_NUM_INW_f2=df_inw.lte_num_of_f2
LTE_RSRP_Count_INW=LTE_NUM_INW_f1+LTE_NUM_INW_f2
LTE_RSRP_AVG_INW=weighted_mean_db(LTE_NUM_INW_f1,df_inw.lte_avg_rsrp_f1,LTE_NUM_INW_f2,df_inw.lte_avg_rsrp_f2)
LTE_RSRP_Max_INW=df_inw[['lte_max_rsrp_f1','lte_max_rsrp_f2']].max(axis=1)
LTE_RSRP_Min_INW=df_inw[['lte_min_rsrp_f1','lte_min_rsrp_f2']].min(axis=1)

LTE_RSSI_Count_INW=LTE_NUM_INW_f1+LTE_NUM_INW_f2
LTE_RSSI_AVG_INW=weighted_mean_db(LTE_NUM_INW_f1,df_inw.lte_avg_rssi_f1,LTE_NUM_INW_f2,df_inw.lte_avg_rssi_f2)
LTE_RSSI_Max_INW=df_inw[['lte_max_rssi_f1','lte_max_rssi_f2']].max(axis=1)
LTE_RSSI_Min_INW=df_inw[['lte_min_rssi_f1','lte_min_rssi_f2']].min(axis=1)

LTE_RSRQ_Count_INW=LTE_NUM_INW_f1+LTE_NUM_INW_f2
LTE_RSRQ_AVG_INW=weighted_mean_db(LTE_NUM_INW_f1,df_inw.lte_avg_rsrq_f1,LTE_NUM_INW_f2,df_inw.lte_avg_rsrq_f2)
LTE_RSRQ_Max_INW=df_inw[['lte_max_rsrq_f1','lte_max_rsrq_f2']].max(axis=1)
LTE_RSRQ_Min_INW=df_inw[['lte_min_rsrq_f1','lte_min_rsrq_f2']].min(axis=1)




# Outdoors

LTE_NUM_O_f1=df_o.lte_num_of_f1
LTE_NUM_O_f2=df_o.lte_num_of_f2
LTE_RSRP_Count_O=LTE_NUM_O_f1+LTE_NUM_O_f2
LTE_RSRP_AVG_O=weighted_mean_db(LTE_NUM_O_f1,df_o.lte_avg_rsrp_f1,LTE_NUM_O_f2,df_o.lte_avg_rsrp_f2)
LTE_RSRP_Max_O=df_o[['lte_max_rsrp_f1','lte_max_rsrp_f2']].max(axis=1)
LTE_RSRP_Min_O=df_o[['lte_min_rsrp_f1','lte_min_rsrp_f2']].min(axis=1)


LTE_RSSI_Count_O=LTE_NUM_O_f1+LTE_NUM_O_f2
LTE_RSSI_AVG_O=weighted_mean_db(LTE_NUM_O_f1,df_o.lte_avg_rssi_f1,LTE_NUM_O_f2,df_o.lte_avg_rssi_f2)
LTE_RSSI_Max_O=df_o[['lte_max_rssi_f1','lte_max_rssi_f2']].max(axis=1)
LTE_RSSI_Min_O=df_o[['lte_min_rssi_f1','lte_min_rssi_f2']].min(axis=1)

LTE_RSRQ_Count_O=LTE_NUM_O_f1+LTE_NUM_O_f2
LTE_RSRQ_AVG_O=weighted_mean_db(LTE_NUM_O_f1,df_o.lte_avg_rsrq_f1,LTE_NUM_O_f2,df_o.lte_avg_rsrq_f2)
LTE_RSRQ_Max_O=df_o[['lte_max_rsrq_f1','lte_max_rsrq_f2']].max(axis=1)
LTE_RSRQ_Min_O=df_o[['lte_min_rsrq_f1','lte_min_rsrq_f2']].min(axis=1)

cols = ['{}'.format(col) for col in ['Max.', 'Min.', 'Avg.']]
rows = ['{}'.format(row) for row in ['Indoors Interrior',"Indoors Near Window", 'Outdoors']]

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))
plt.setp(axes.flat, xlabel='RSRQ (dBm)', ylabel='RSRP (dBm)')

pad = 5 # in points

for ax, col in zip(axes[0], cols):
    ax.annotate(col, xy=(0.5, 1), xytext=(0, pad),
                xycoords='axes fraction', textcoords='offset points',
                size='large', ha='center', va='baseline')

for ax, row in zip(axes[:,0], rows):
    ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
                xycoords=ax.yaxis.label, textcoords='offset points',
                size='large', ha='right', va='center')

fig.tight_layout()
# tight_layout doesn't take these labels into account. We'll need
# to make some room. These numbers are are manually tweaked.
# You could automatically calculate them, but it's a pain.

# Indoors

axes[0,0].scatter(LTE_RSRQ_Max_II,LTE_RSRP_Max_II)
axes[0,0].set_xlim((-30,0))

axes[1,0].scatter(LTE_RSRQ_Max_INW,LTE_RSRP_Max_INW)
axes[1,0].set_xlim((-30,0))

axes[2,0].scatter(LTE_RSRQ_Max_O,LTE_RSRP_Max_O)
axes[2,0].set_xlim((-30,0))

axes[0,1].scatter(LTE_RSRQ_Min_II,LTE_RSRP_Min_II)
axes[0,1].set_xlim((-30,0))

axes[1,1].scatter(LTE_RSRQ_Min_INW,LTE_RSRP_Min_INW)
axes[1,1].set_xlim((-30,0))

axes[2,1].scatter(LTE_RSRQ_Min_O,LTE_RSRP_Min_O)
axes[2,1].set_xlim((-30,0))

axes[0,2].scatter(LTE_RSRQ_AVG_II,LTE_RSRP_AVG_II)
axes[0,2].set_xlim((-30,0))

axes[1,2].scatter(LTE_RSRQ_AVG_INW,LTE_RSRP_AVG_INW)
axes[1,2].set_xlim((-30,0))

axes[2,2].scatter(LTE_RSRQ_AVG_O,LTE_RSRP_AVG_O)
axes[2,2].set_xlim((-30,0))

# Indoors

NR_NUM_II_f1=df_ii.nr_num_of_f1
NR_NUM_II_f2=df_ii.nr_num_of_f2
NR_RSRP_Count_II=NR_NUM_II_f1+NR_NUM_II_f2
NR_RSRP_AVG_II=weighted_mean_db(NR_NUM_II_f1,df_ii.nr_avg_rsrp_f1,NR_NUM_II_f2,df_ii.nr_avg_rsrp_f2)
NR_RSRP_Max_II=df_ii[['nr_max_rsrp_f1','nr_max_rsrp_f2']].max(axis=1)
NR_RSRP_Min_II=df_ii[['nr_min_rsrp_f1','nr_min_rsrp_f2']].min(axis=1)

NR_RSSI_Count_II=NR_NUM_II_f1+NR_NUM_II_f2
NR_RSSI_AVG_II=weighted_mean_db(NR_NUM_II_f1,df_ii.nr_avg_rssi_f1,NR_NUM_II_f2,df_ii.nr_avg_rssi_f2)
NR_RSSI_Max_II=df_ii[['nr_max_rssi_f1','nr_max_rssi_f2']].max(axis=1)
NR_RSSI_Min_II=df_ii[['nr_min_rssi_f1','nr_min_rssi_f2']].min(axis=1)

NR_RSRQ_Count_II=NR_NUM_II_f1+NR_NUM_II_f2
NR_RSRQ_AVG_II=weighted_mean_db(NR_NUM_II_f1,df_ii.nr_avg_rsrq_f1,NR_NUM_II_f2,df_ii.nr_avg_rsrq_f2)
NR_RSRQ_Max_II=df_ii[['nr_max_rsrq_f1','nr_max_rsrq_f2']].max(axis=1)
NR_RSRQ_Min_II=df_ii[['nr_min_rsrq_f1','nr_min_rsrq_f2']].min(axis=1)


# Indoors NW

NR_NUM_INW_f1=df_inw.nr_num_of_f1
NR_NUM_INW_f2=df_inw.nr_num_of_f2
NR_RSRP_Count_INW=NR_NUM_INW_f1+NR_NUM_INW_f2
NR_RSRP_AVG_INW=weighted_mean_db(NR_NUM_INW_f1,df_inw.nr_avg_rsrp_f1,NR_NUM_INW_f2,df_inw.nr_avg_rsrp_f2)
NR_RSRP_Max_INW=df_inw[['nr_max_rsrp_f1','nr_max_rsrp_f2']].max(axis=1)
NR_RSRP_Min_INW=df_inw[['nr_min_rsrp_f1','nr_min_rsrp_f2']].min(axis=1)

NR_RSSI_Count_INW=NR_NUM_INW_f1+NR_NUM_INW_f2
NR_RSSI_AVG_INW=weighted_mean_db(NR_NUM_INW_f1,df_inw.nr_avg_rssi_f1,NR_NUM_INW_f2,df_inw.nr_avg_rssi_f2)
NR_RSSI_Max_INW=df_inw[['nr_max_rssi_f1','nr_max_rssi_f2']].max(axis=1)
NR_RSSI_Min_INW=df_inw[['nr_min_rssi_f1','nr_min_rssi_f2']].min(axis=1)

NR_RSRQ_Count_INW=NR_NUM_INW_f1+NR_NUM_INW_f2
NR_RSRQ_AVG_INW=weighted_mean_db(NR_NUM_INW_f1,df_inw.nr_avg_rsrq_f1,NR_NUM_INW_f2,df_inw.nr_avg_rsrq_f2)
NR_RSRQ_Max_INW=df_inw[['nr_max_rsrq_f1','nr_max_rsrq_f2']].max(axis=1)
NR_RSRQ_Min_INW=df_inw[['nr_min_rsrq_f1','nr_min_rsrq_f2']].min(axis=1)



# Outdoors

NR_NUM_O_f1=df_o.nr_num_of_f1
NR_NUM_O_f2=df_o.nr_num_of_f2
NR_RSRP_Count_O=NR_NUM_O_f1+NR_NUM_O_f2
NR_RSRP_AVG_O=weighted_mean_db(NR_NUM_O_f1,df_o.nr_avg_rsrp_f1,NR_NUM_O_f2,df_o.nr_avg_rsrp_f2)
NR_RSRP_Max_O=df_o[['nr_max_rsrp_f1','nr_max_rsrp_f2']].max(axis=1)
NR_RSRP_Min_O=df_o[['nr_min_rsrp_f1','nr_min_rsrp_f2']].min(axis=1)

NR_RSSI_Count_O=NR_NUM_O_f1+NR_NUM_O_f2
NR_RSSI_AVG_O=weighted_mean_db(NR_NUM_O_f1,df_o.nr_avg_rssi_f1,NR_NUM_O_f2,df_o.nr_avg_rssi_f2)
NR_RSSI_Max_O=df_o[['nr_max_rssi_f1','nr_max_rssi_f2']].max(axis=1)
NR_RSSI_Min_O=df_o[['nr_min_rssi_f1','nr_min_rssi_f2']].min(axis=1)

NR_RSRQ_Count_O=NR_NUM_O_f1+NR_NUM_O_f2
NR_RSRQ_AVG_O=weighted_mean_db(NR_NUM_O_f1,df_o.nr_avg_rsrq_f1,NR_NUM_O_f2,df_o.nr_avg_rsrq_f2)
NR_RSRQ_Max_O=df_o[['nr_max_rsrq_f1','nr_max_rsrq_f2']].max(axis=1)
NR_RSRQ_Min_O=df_o[['nr_min_rsrq_f1','nr_min_rsrq_f2']].min(axis=1)

cols = ['{}'.format(col) for col in ['Max.', 'Min.', 'Avg.']]
rows = ['{}'.format(row) for row in ['Indoors Interriot','Indoors Near Window', 'Outdoors']]

fig, axes = plt.subplots(nrows=3, ncols=3, figsize=(12, 8))
plt.setp(axes.flat, xlabel='RSRQ (dBm)', ylabel='RSRP (dBm)')

pad = 5 # in points

for ax, col in zip(axes[0], cols):
    ax.annotate(col, xy=(0.5, 1), xytext=(0, pad),
                xycoords='axes fraction', textcoords='offset points',
                size='large', ha='center', va='baseline')

for ax, row in zip(axes[:,0], rows):
    ax.annotate(row, xy=(0, 0.5), xytext=(-ax.yaxis.labelpad - pad, 0),
                xycoords=ax.yaxis.label, textcoords='offset points',
                size='large', ha='right', va='center')

fig.tight_layout()
# tight_layout doesn't take these labels into account. We'll need
# to make some room. These numbers are are manually tweaked.
# You could automatically calculate them, but it's a pain.

axes[0,0].scatter(NR_RSRQ_Max_II,NR_RSRP_Max_II)
axes[0,0].set_xlim((-30,0))

axes[1,0].scatter(NR_RSRQ_Max_INW,NR_RSRP_Max_INW)
axes[1,0].set_xlim((-30,0))

axes[2,0].scatter(NR_RSRQ_Max_O,NR_RSRP_Max_O)
axes[2,0].set_xlim((-30,0))

axes[0,1].scatter(NR_RSRQ_Min_II,NR_RSRP_Min_II)
axes[0,1].set_xlim((-30,0))

axes[1,1].scatter(NR_RSRQ_Min_INW,NR_RSRP_Min_INW)
axes[1,1].set_xlim((-30,0))

axes[2,1].scatter(NR_RSRQ_Min_O,NR_RSRP_Min_O)
axes[2,1].set_xlim((-30,0))

axes[0,2].scatter(NR_RSRQ_AVG_II,NR_RSRP_AVG_II)
axes[0,2].set_xlim((-30,0))

axes[1,2].scatter(NR_RSRQ_AVG_INW,NR_RSRP_AVG_INW)
axes[1,2].set_xlim((-30,0))

axes[2,2].scatter(NR_RSRQ_AVG_O,NR_RSRP_AVG_O)
axes[2,2].set_xlim((-30,0))



"""Bot plox

"""

Out_count_lte_f1=df_o.lte_num_of_f1
II_count_lte_f1=df_ii.lte_num_of_f1
INW_count_lte_f1=df_inw.lte_num_of_f1

Out_count_lte_f2=df_o.lte_num_of_f2
II_count_lte_f2=df_ii.lte_num_of_f2
INW_count_lte_f2=df_inw.lte_num_of_f2

# Combine the data into a list
data = [Out_count_lte_f1, II_count_lte_f1, INW_count_lte_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'],fontsize='x-large')

# Adding labels and title

plt.ylabel('Number of unique PCIs',fontsize='x-large')
plt.grid('true')
plt.xlabel('Location type',fontsize='x-large')
ax.yaxis.set_major_locator(MaxNLocator(integer=True))
# Show the plot
plt.show()



np.unique(INW_count_lte_f2)

# Combine the data into a list
data = [Out_count_lte_f2, II_count_lte_f2, INW_count_lte_f2]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'],fontsize='x-large')

# Adding labels and title

plt.ylabel('Number of unique PCIs',fontsize='x-large')
plt.xlabel('Location type',fontsize='x-large')
ax.yaxis.set_major_locator(MaxNLocator(integer=True))
plt.grid('true')
# Show the plot
plt.show()

np.unique(INW_count_lte_f1)

# Combine the data into a list
data = [Out_count_nr_f1, II_count_nr_f1, INW_count_nr_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Number of unique PCIs')
plt.grid('true')
plt.xlabel('Location type')

# Show the plot
plt.show()

# Combine the data into a list
data = [Out_count_lte_f1, II_count_lte_f1, INW_count_lte_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Number of unique PCIs')
plt.grid('true')
plt.xlabel('Location type')
plt.xlabel('Location type')

# Show the plot
plt.show()

Out_count_nr_f1=df_o.nr_num_of_f1
II_count_nr_f1=df_ii.nr_num_of_f1
INW_count_nr_f1=df_inw.nr_num_of_f1

Out_count_nr_f2=df_o.nr_num_of_f2
II_count_nr_f2=df_ii.nr_num_of_f2
INW_count_nr_f2=df_inw.nr_num_of_f2



Out_max_lte_f1 = df_o.lte_max_rsrp_f1
II_max_lte_f1 = df_ii.lte_max_rsrp_f1
INW_max_lte_f1 = df_inw.lte_max_rsrp_f1

Out_max_lte_f2 = df_o.lte_max_rsrp_f1
II_max_lte_f2 = df_ii.lte_max_rsrp_f2
INW_max_lte_f2 = df_inw.lte_max_rsrp_f2

# Combine the data into a list
data = [Out_max_lte_f1, II_max_lte_f1, INW_max_lte_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Max of RSSI(dBm)')
plt.grid('true')

plt.xlabel('Location type')
# Show the plot
plt.show()

Out_min_lte_f1 = df_o['lte_min_rsrp_f1']
II_min_lte_f1 = df_ii['lte_min_rsrp_f1']
INW_min_lte_f1 = df_inw['lte_min_rsrp_f1']

Out_min_lte_f2 = df_o['lte_min_rsrp_f2']  # Corrected to f2 for consistency
II_min_lte_f2 = df_ii['lte_min_rsrp_f2']
INW_min_lte_f2 = df_inw['lte_min_rsrp_f2']

# Combine the data into a list
data = [Out_min_lte_f1, II_min_lte_f1, INW_min_lte_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Min of RSSI(dBm)')
plt.grid('true')

plt.xlabel('Location type')
# Show the plot
plt.show()

# Filter out non-negative values for LTE average RSRP for f1
Out_avg_lte_f1 = df_o[df_o['lte_avg_rsrp_f1'] < 0]['lte_avg_rsrp_f1']
II_avg_lte_f1 = df_ii[df_ii['lte_avg_rsrp_f1'] < 0]['lte_avg_rsrp_f1']
INW_avg_lte_f1 = df_inw[df_inw['lte_avg_rsrp_f1'] < 0]['lte_avg_rsrp_f1']

# Filter out non-negative values for LTE average RSRP for f2
Out_avg_lte_f2 = df_o[df_o['lte_avg_rsrp_f2'] < 0]['lte_avg_rsrp_f2']
II_avg_lte_f2 = df_ii[df_ii['lte_avg_rsrp_f2'] < 0]['lte_avg_rsrp_f2']
INW_avg_lte_f2 = df_inw[df_inw['lte_avg_rsrp_f2'] < 0]['lte_avg_rsrp_f2']

# Combine the data into a list
data = [Out_avg_lte_f1, II_avg_lte_f1, INW_avg_lte_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Avg. of RSRP(dBm)')
plt.grid('true')
plt.xlabel('Location type')

# Show the plot
plt.show()

# Filter out non-negative values for NR average RSRP for f1
Out_avg_nr_f1 = df_o[df_o['nr_avg_rsrp_f1'] < 0]['nr_avg_rsrp_f1']
II_avg_nr_f1 = df_ii[df_ii['nr_avg_rsrp_f1'] < 0]['nr_avg_rsrp_f1']
INW_avg_nr_f1 = df_inw[df_inw['nr_avg_rsrp_f1'] < 0]['nr_avg_rsrp_f1']

# Filter out non-negative values for NR average RSRP for f2
Out_avg_nr_f2 = df_o[df_o['nr_avg_rsrp_f2'] < 0]['nr_avg_rsrp_f2']
II_avg_nr_f2 = df_ii[df_ii['nr_avg_rsrp_f2'] < 0]['nr_avg_rsrp_f2']
INW_avg_nr_f2 = df_inw[df_inw['nr_avg_rsrp_f2'] < 0]['nr_avg_rsrp_f2']

# Combine the data into a list
data = [Out_avg_nr_f1, II_avg_nr_f1, INW_avg_nr_f1]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Avg. of RSRP(dBm)')
plt.grid('true')


# Show the plot
plt.show()

# Combine the data into a list
data = [Out_avg_lte_f2, II_avg_lte_f2, INW_avg_lte_f2]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Avg. of RSRP(dBm)')
plt.grid('true')
plt.xlabel('Location type')

# Show the plot
plt.show()

# Combine the data into a list
data = [Out_avg_nr_f2, II_avg_nr_f2, INW_avg_nr_f2]

# Colors for the boxplots
colors = ['red', 'blue', 'green']

# Create a figure and a set of subplots
fig, ax = plt.subplots()

# Create the boxplot with color customization
bp = ax.boxplot(data, patch_artist=True)  # patch_artist must be True to fill with color

# Coloring each box
for patch, color in zip(bp['boxes'], colors):
    patch.set_facecolor(color)

# Set the x-tick labels
ax.set_xticklabels(['O', 'II', 'INW'])

# Adding labels and title

plt.ylabel('Avg. of RSRP(dBm)')
plt.grid('true')


# Show the plot
plt.show()

np.unique(df_ii.nr_max_rssi_f2)

